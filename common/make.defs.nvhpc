#
# This file shows the NVHPC toolchain options.
NVHPC_PATH=${HOME}/NVIDIA/hpc_sdk/Linux_x86_64/2021
#
# Base compilers and language options
#
# C99 is required in some implementations.
CC=${NVHPC_PATH}/compilers/bin/nvc -c11
# All of the Fortran code is written for the 2008 standard and requires preprocessing.
FC=${NVHPC_PATH}/compilers/bin/nvfortran -acc -gpu=managed -cuda -cudalib -target=gpu -DNVHPC
# C++11 may not be required but does no harm here.
CXX=${NVHPC_PATH}/compilers/bin/nvc++ --c++17
#
# Compiler flags
#
DEFAULT_OPT_FLAGS=-O2
DEFAULT_OPT_FLAGS+=-Wall #-Werror
#
# OpenMP flags
#
OPENMPFLAG=-mp
#OPENMPFLAG+=-Minfo=mp,vect
OPENMPSIMDFLAG=
OFFLOADFLAG=-mp -target=gpu
OFFLOADFLAG+=-Minfo=accel
OFFLOADFLAG+=-DGPU_SCHEDULE="schedule(static,1)"
OPENACCFLAG=-acc -target=gpu
OPENACCFLAG+=-Mlarge_arrays
OPENACCFLAG+=-Minfo=accel
STDPARFLAG=-stdpar -Minfo=accel
#
# OpenCL flags
#
OPENCLDIR=/usr/local/cuda-11.2/targets/x86_64-linux
OPENCLFLAG=-I${OPENCLDIR}/include -L${OPENCLDIR}/lib -lOpenCL
#OPENCLFLAG+=-Wno-ignored-attributes -Wno-deprecated-declarations
#OPENCLFLAG+=-Wno-deprecated-declarations -Wno-missing-braces
#
#
# Parallel STL, Boost, etc.
#
BOOSTFLAG=-I/usr/local/Cellar/boost/1.69.0_2/include
RANGEFLAG=-DUSE_BOOST_IRANGE ${BOOSTFLAG}
#RANGEFLAG=-DUSE_RANGES_TS -I./range-v3/include
PSTLFLAG=${OPENMPSIMDFLAG} ${TBBFLAG} -I./pstl/include ${RANGEFLAG}
KOKKOSDIR=
KOKKOSFLAG=-I${KOKKOSDIR}/include -L${KOKKOSDIR}/lib -lkokkos ${OPENMPFLAG}
RAJADIR=
RAJAFLAG=-I${RAJADIR}/include -L${RAJADIR}/lib -lRAJA ${OPENMPFLAG} ${TBBFLAG}
THRUSTDIR=/opt/nvidia/thrust
THRUSTFLAG=-I${THRUSTDIR} ${RANGEFLAG}
#
# CBLAS for C++ DGEMM
#
BLASFLAG=
CBLASFLAG=
#
# CUDA flags
#
# Linux w/ NVIDIA CUDA
# Use appropriate arch or code is compiled to ancient features.
NVCC=${NVHPC_PATH}/compilers/bin/nvcc
CUDAFLAGS=-g -O3 -std=c++11
CUDAFLAGS+=--gpu-architecture=sm_70
#CUDAFLAGS+=--compiler-bindir=/swtools/gcc/7.5.0/bin
#CUDAFLAGS+=-forward-unknown-to-host-compiler -fopenmp
CUDAFLAGS+=-rdc=true # FIXES ptxas fatal   : Unresolved extern function 'cudaCGGetIntrinsicHandle'
# https://github.com/tensorflow/tensorflow/issues/1066#issuecomment-200574233
# heavy hammer:
CUDAFLAGS+=-D_X86INTRIN_H_INCLUDED
# big hammers:
#CUDAFLAGS+=-D_IMMINTRIN_H_INCLUDED
#CUDAFLAGS+=-D_FMA4INTRIN_H_INCLUDED
#CUDAFLAGS+=-D_XOPMMINTRIN_H_INCLUDED
# many tiny hammers:
#CUDAFLAGS+=-D_MWAITXINTRIN_H_INCLUDED
#CUDAFLAGS+=-D_AVX512FINTRIN_H_INCLUDED
#CUDAFLAGS+=-D_AVX512VLINTRIN_H_INCLUDED
#CUDAFLAGS+=-D_AVX512BWINTRIN_H_INCLUDED
#CUDAFLAGS+=-D_AVX512DQINTRIN_H_INCLUDED
#CUDAFLAGS+=-D_AVX512VLBWINTRIN_H_INCLUDED
#CUDAFLAGS+=-D_AVX512VBMIVLINTRIN_H_INCLUDED
#CUDAFLAGS+=-D_AVX512VBMIINTRIN_H_INCLUDED
#CUDAFLAGS+=-D_AVX512VLDQINTRIN_H_INCLUDED
#CUDAFLAGS+=-D_AVX512CDINTRIN_H_INCLUDED
#CUDAFLAGS+=-D_AVX512PFINTRIN_H_INCLUDED
#CUDAFLAGS+=-D_AVX512IFMAINTRIN_H_INCLUDED
#CUDAFLAGS+=-D_AVX512IFMAVLINTRIN_H_INCLUDED
#CUDAFLAGS+=-D_AVX512ERINTRIN_H_INCLUDED
#
# MPI-3
#
# mpiicc wraps icc.  mpicc and mpigcc wrap gcc.
MPIDIR=${NVHPC_PATH}/comm_libs/openmpi/openmpi-3.1.5
MPICC=${MPIDIR}/bin/mpicc
MPICXX=${MPIDIR}/bin/mpicxx
MPIINC=-I${MPIDIR}/include
MPILIB=-L${MPIDIR}/lib -lmpi
#MPILIB=-L/usr/local/opt/libevent/lib -L${MPIDIR}/lib -lmpi
#MPIINC=-I/usr/include/mpich-3.2-x86_64
#MPILIB=-L/usr/lib64/mpich-3.2/lib -lmpi
#
# Global Arrays
#
GADIR=../deps/ga
GAFLAG=-I${GADIR}/include
GAFLAG+=-L${GADIR}/lib -lga
GAFLAG+=-L${GADIR}/../armci-mpi/lib -larmci # ARMCI-MPI
#GAFLAG+=-L${GADIR}/lib -larmci -lcomex     # ARMCI/ComEx
GAFLAG+=${MPIINC} ${MPILIB}
GAFLAG+=-lmpifort -lmpi
GAFLAG+=-i8 # GA is compiled with -i8 on 64-bit systems
#
# PETSc
#
PETSCDIR=../deps/petsc
PETSCFLAG=-I${PETSCDIR}/include
PETSCFLAG+=-L${PETSCDIR}/lib -lpetsc
PETSCFLAG+=-Wl,-rpath=${PETSCDIR}/lib
#
# Fortran 2008 coarrays
#
# see https://github.com/ParRes/Kernels/blob/master/FORTRAN/README.md for details
# single-node
#COARRAYFLAG=-fcoarray=single -lcaf_single
# multi-node
# COARRAYFLAG=-fcoarray=lib -lcaf_mpi

